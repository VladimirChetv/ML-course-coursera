{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание задачи\n",
    "\n",
    "Небольшой интернет-магазин попросил вас добавить ранжирование товаров в блок \"Смотрели ранее\" - в нем теперь надо показывать не последние просмотренные пользователем товары, а те товары из просмотренных, которые он наиболее вероятно купит. Качество вашего решения будет оцениваться по количеству покупок в сравнении с прошлым решением в ходе А/В теста, т.к. по доходу от продаж статзначимость будет достигаться дольше из-за разброса цен. Таким образом, ничего заранее не зная про корреляцию оффлайновых и онлайновых метрик качества, в начале проекта вы можете лишь постараться оптимизировать recall@k и precision@k.\n",
    "\n",
    "Это задание посвящено построению простых бейзлайнов для этой задачи: ранжирование просмотренных товаров по частоте просмотров и по частоте покупок. Эти бейзлайны, с одной стороны, могут помочь вам грубо оценить возможный эффект от ранжирования товаров в блоке - например, чтобы вписать какие-то числа в коммерческое предложение заказчику, а с другой стороны, могут оказаться самым хорошим вариантом, если данных очень мало (недостаточно для обучения даже простых моделей).\n",
    "\n",
    "Входные данные\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - id-шниками просмотренных и id-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: id просмотренных товаров через , затем идёт ; после чего следуют id купленных товаров (если такие имеются), разделённые запятой. Например, 1,2,3,4; или 1,2,3,4;5,6.\n",
    "\n",
    "Гарантируется, что среди id купленных товаров все различные.\n",
    "\n",
    "Важно:\n",
    "\n",
    "- Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "- Если товар не встречался в обучающей выборке, его популярность равна 0.\n",
    "- Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "- Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "\n",
    "1) На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать.\n",
    "\n",
    "2) Реализуйте два алгоритма рекомендаций:\n",
    "- сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "- сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "\n",
    "3) Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)\n",
    "\n",
    "Дополнительные вопросы\n",
    "\n",
    "1) Обратите внимание, что при сортировке по покупаемости возникает много товаров с одинаковым рангом - это означает, что значение метрик будет зависеть от того, как мы будем сортировать товары с одинаковым рангом. Попробуйте убедиться, что при изменении сортировки таких товаров recall@k меняется. Подумайте, как оценить минимальное и максимальное значение recall@k в зависимости от правила сортировки.\n",
    "\n",
    "2) Мы обучаемся и тестируемся на полных сессиях (в которых есть все просмотренные за сессию товары). Подумайте, почему полученная нами оценка качества рекомендаций в этом случае несколько завышена.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'r') as f:\n",
    "    train = f.read().splitlines()\n",
    "with open('test.txt', 'r') as f:\n",
    "    test = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = []\n",
    "\n",
    "for tr in train:\n",
    "    visit, perchases = tr.split(';')\n",
    "    visit = list(map(int, visit.split(',')))\n",
    "    if perchases != '':\n",
    "        perchase = list(map(int,perchases.split(',')))\n",
    "    else:\n",
    "        perchase = []\n",
    "    train_split.append([visit, perchase])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_split = []\n",
    "for tr in test:\n",
    "    visit, perchases = tr.split(';')\n",
    "    visit = list(map(int, visit.split(',')))\n",
    "    if perchases != '':\n",
    "        perchase = list(map(int,perchases.split(',')))\n",
    "    else:\n",
    "        perchase = []\n",
    "    test_split.append([visit, perchase])\n",
    "\n",
    "len(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      6],\n",
       "       [     1,      6],\n",
       "       [     2,      9],\n",
       "       ...,\n",
       "       [102804,      1],\n",
       "       [102805,      1],\n",
       "       [102806,      1]], dtype=int64)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_train_l = [row[0] for row in train_split]\n",
    "visit_train_np = np.array( [id_n for visit in visit_train_l for id_n in visit] )\n",
    "\n",
    "visit_train_unique = np.transpose(np.unique(visit_train_np, return_counts=True))\n",
    "visit_train_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32291, 60520, 32291, 38220]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_train_l[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     5,      1],\n",
       "       [     6,      2],\n",
       "       [     7,      2],\n",
       "       ...,\n",
       "       [102417,      1],\n",
       "       [102462,      1],\n",
       "       [102646,      1]], dtype=int64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perchase_train_l = [row[1] for row in train_split]\n",
    "perchase_train_np = np.array( [id_n for perchase in perchase_train_l for id_n in perchase] )\n",
    "\n",
    "perchase_train_unique = np.transpose(np.unique(perchase_train_np, return_counts=True))\n",
    "perchase_train_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_train_unique.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_train_unique = visit_train_unique[visit_train_unique[:,1].argsort()][::-1]\n",
    "perchase_train_unique = perchase_train_unique[perchase_train_unique[:,1].argsort()][::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    73,    677],\n",
       "       [   158,    641],\n",
       "       [   204,    396],\n",
       "       ...,\n",
       "       [ 73827,      1],\n",
       "       [ 73828,      1],\n",
       "       [102806,      1]], dtype=int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_train_unique_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  158,    14],\n",
       "       [  204,    12],\n",
       "       [   73,    11],\n",
       "       ...,\n",
       "       [38189,     1],\n",
       "       [38177,     1],\n",
       "       [    5,     1]], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perchase_train_unique_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_rec_metrics(session, reccomendations, k):\n",
    "    purchase = 0\n",
    "    for ind in reccomendations:\n",
    "        if ind in session:\n",
    "            purchase += 1 \n",
    "    precision = purchase / k\n",
    "    recall = purchase / len(session)\n",
    "    return(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# По просмотрам\n",
    "prec_at_1_tr_l, rec_at_1_tr_l = [], []\n",
    "prec_at_5_tr_l, rec_at_5_tr_l = [], []\n",
    "k1, k5 = 1, 5\n",
    "for i, sess_perchase in enumerate(perchase_train_l):\n",
    "    # Пропускаем пустые\n",
    "    if sess_perchase == []: continue\n",
    "    \n",
    "    # visit ids, где perchare != ''\n",
    "    sess_l = visit_train_l[i]\n",
    "\n",
    "    # sorted looks ids indices in sess_train_l_cnt array\n",
    "    # sort in accordance with looks counts\n",
    "    l_ind_sess = []\n",
    "    for j in range(len(sess_l)):\n",
    "        l_ind_sess.append(np.where(visit_train_unique[:,0] == sess_l[j])[0][0])\n",
    "    l_ind_sess_sorted = np.unique(l_ind_sess)\n",
    "    \n",
    "    num_of_recs_k1 = min(k1, len(sess_l))\n",
    "    if num_of_recs_k1 == 0: continue\n",
    "    recs_k1 = visit_train_unique[l_ind_sess_sorted[:num_of_recs_k1],0]\n",
    "    \n",
    "    num_of_recs_k5 = min(k5, len(sess_l))\n",
    "    if num_of_recs_k5 == 0: continue\n",
    "    recs_k5 = visit_train_unique[l_ind_sess_sorted[:num_of_recs_k5],0]\n",
    "    \n",
    "    prec_1, rec_1 = prec_rec_metrics(sess_perchase, recs_k1, k1)\n",
    "    prec_at_1_tr_l.append(prec_1)\n",
    "    rec_at_1_tr_l.append(rec_1)\n",
    "    \n",
    "    prec_5, rec_5 = prec_rec_metrics(sess_perchase, recs_k5, k5)\n",
    "    prec_at_5_tr_l.append(prec_5)\n",
    "    rec_at_5_tr_l.append(rec_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4383013528107763"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_at_1_tr_l = np.mean(prec_at_1_tr_l)\n",
    "avg_rec_at_1_tr_l = np.mean(rec_at_1_tr_l)\n",
    "avg_prec_at_5_tr_l = np.mean(prec_at_5_tr_l)\n",
    "avg_rec_at_5_tr_l = np.mean(rec_at_5_tr_l)\n",
    "avg_rec_at_1_tr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1: 0.44 0.51 0.83 0.21\n"
     ]
    }
   ],
   "source": [
    "with open('ans1.txt', 'w') as f:\n",
    "    r1 = '%.2f' % round(avg_rec_at_1_tr_l, 2)\n",
    "    p1 = '%.2f' % round(avg_prec_at_1_tr_l, 2)\n",
    "    r5 = '%.2f' % round(avg_rec_at_5_tr_l, 2)\n",
    "    p5 = '%.2f' % round(avg_prec_at_5_tr_l, 2)\n",
    "    ans1 = ' '.join([r1, p1, r5, p5])\n",
    "    print('Answer 1:', ans1)\n",
    "    f.write(ans1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_1_tr_l, rec_at_1_tr_l = [], []\n",
    "prec_at_5_tr_l, rec_at_5_tr_l = [], []\n",
    "k1, k5 = 1, 5\n",
    "for i, sess_perchase in enumerate(perchase_train_l):\n",
    "    # Пропускаем пустые\n",
    "    if sess_perchase == []: continue\n",
    "    \n",
    "    # visit ids, где perchare != ''\n",
    "    sess_l = visit_train_l[i]\n",
    "\n",
    "    # sorted looks ids indices in sess_train_l_cnt array\n",
    "    # sort in accordance with looks counts\n",
    "    l_ind_sess = []\n",
    "    for j in range(len(sess_l)):\n",
    "        if sess_l[j] not in perchase_train_unique[:,0]: continue\n",
    "        l_ind_sess.append(np.where(perchase_train_unique[:,0] == sess_l[j])[0][0])\n",
    "    l_ind_sess_sorted = np.unique(l_ind_sess)\n",
    "    \n",
    "    num_of_recs_k1 = min(k1, len(sess_l), len(l_ind_sess_sorted))\n",
    "    if num_of_recs_k1 == 0: continue\n",
    "    recs_k1 = perchase_train_unique[l_ind_sess_sorted[:num_of_recs_k1],0]\n",
    "    \n",
    "    num_of_recs_k5 = min(k5, len(sess_l), len(l_ind_sess_sorted))\n",
    "    if num_of_recs_k5 == 0: continue\n",
    "    recs_k5 = perchase_train_unique[l_ind_sess_sorted[:num_of_recs_k5],0]\n",
    "    \n",
    "    prec_1, rec_1 = prec_rec_metrics(sess_perchase, recs_k1, k1)\n",
    "    prec_at_1_tr_l.append(prec_1)\n",
    "    rec_at_1_tr_l.append(rec_1)\n",
    "    \n",
    "    prec_5, rec_5 = prec_rec_metrics(sess_perchase, recs_k5, k5)\n",
    "    prec_at_5_tr_l.append(prec_5)\n",
    "    rec_at_5_tr_l.append(rec_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.677355817184901"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_at_1_tr_l = np.mean(prec_at_1_tr_l)\n",
    "avg_rec_at_1_tr_l = np.mean(rec_at_1_tr_l)\n",
    "avg_prec_at_5_tr_l = np.mean(prec_at_5_tr_l)\n",
    "avg_rec_at_5_tr_l = np.mean(rec_at_5_tr_l)\n",
    "avg_rec_at_1_tr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2: 0.68 0.79 0.93 0.25\n"
     ]
    }
   ],
   "source": [
    "with open('ans2.txt', 'w') as f:\n",
    "    r1 = '%.2f' % round(avg_rec_at_1_tr_l, 2)\n",
    "    p1 = '%.2f' % round(avg_prec_at_1_tr_l, 2)\n",
    "    r5 = '%.2f' % round(avg_rec_at_5_tr_l, 2)\n",
    "    p5 = '%.2f' % round(avg_prec_at_5_tr_l, 2)\n",
    "    ans2 = ' '.join([r1, p1, r5, p5])\n",
    "    print('Answer 2:', ans2)\n",
    "    f.write(ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_test_l = [row[0] for row in test_split]\n",
    "visit_test_np = np.array( [id_n for visit in visit_test_l for id_n in visit] )\n",
    "\n",
    "#visit_test_unique = np.transpose(np.unique(visit_test_np, return_counts=True))\n",
    "#visit_test_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "perchase_test_l = [row[1] for row in test_split]\n",
    "perchase_test_np = np.array( [id_n for perchase in perchase_test_l for id_n in perchase] )\n",
    "\n",
    "#perchase_test_unique = np.transpose(np.unique(perchase_test_np, return_counts=True))\n",
    "#perchase_test_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_test_unique = visit_test_unique[visit_test_unique[:,1].argsort()][::-1]\n",
    "perchase_test_unique = perchase_test_unique[perchase_test_unique[:,1].argsort()][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# По просмотрам\n",
    "prec_at_1_tst_l, rec_at_1_tst_l = [], []\n",
    "prec_at_5_tst_l, rec_at_5_tst_l = [], []\n",
    "k1, k5 = 1, 5\n",
    "for i, sess_perchase in enumerate(perchase_test_l):\n",
    "    # Пропускаем пустые\n",
    "    if sess_perchase == []: continue\n",
    "    \n",
    "    # visit ids, где perchare != ''\n",
    "    sess_l = visit_test_l[i]\n",
    "\n",
    "    # sorted looks ids indices in sess_train_l_cnt array\n",
    "    # sort in accordance with looks counts\n",
    "    l_ind_sess = []\n",
    "    new_ids = []\n",
    "    for j in range(len(sess_l)):\n",
    "        if sess_l[j] not in visit_train_unique[:,0]:\n",
    "            new_ids.append(sess_l[j])\n",
    "            continue\n",
    "        l_ind_sess.append(np.where(visit_train_unique[:,0] == sess_l[j])[0][0])\n",
    "    l_ind_sess_sorted = np.unique(l_ind_sess)\n",
    "    \n",
    "    num_of_recs_k1 = min(k1, len(sess_l))\n",
    "    if num_of_recs_k1 == 0: continue\n",
    "    if l_ind_sess != []:\n",
    "        recs_k1 = visit_train_unique[l_ind_sess_sorted[:num_of_recs_k1],0]\n",
    "    else:\n",
    "        recs_k1 = []\n",
    "    recs_k1 = np.concatenate((np.array(recs_k1, dtype='int64'), np.unique(np.array(new_ids, dtype='int64'))))[:num_of_recs_k1]\n",
    "    \n",
    "    num_of_recs_k5 = min(k5, len(sess_l))\n",
    "    if num_of_recs_k5 == 0: continue\n",
    "    if l_ind_sess != []:\n",
    "        recs_k5 = visit_train_unique[l_ind_sess_sorted[:num_of_recs_k5],0]\n",
    "    else:\n",
    "        recs_k5 = []\n",
    "    recs_k5 = np.concatenate((np.array(recs_k5, dtype='int64'), np.unique(np.array(new_ids, dtype='int64'))))[:num_of_recs_k5]\n",
    "    \n",
    "    prec_1, rec_1 = prec_rec_metrics(sess_perchase, recs_k1, k1)\n",
    "    prec_at_1_tst_l.append(prec_1)\n",
    "    rec_at_1_tst_l.append(rec_1)\n",
    "    \n",
    "    prec_5, rec_5 = prec_rec_metrics(sess_perchase, recs_k5, k5)\n",
    "    prec_at_5_tst_l.append(prec_5)\n",
    "    rec_at_5_tst_l.append(rec_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03128694861300591"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_at_1_tst_l = np.mean(prec_at_1_tst_l)\n",
    "avg_rec_at_1_tst_l = np.mean(rec_at_1_tst_l)\n",
    "avg_prec_at_5_tst_l = np.mean(prec_at_5_tst_l)\n",
    "avg_rec_at_5_tst_l = np.mean(rec_at_5_tst_l)\n",
    "avg_rec_at_1_te_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-216-c6657aead2f8>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-216-c6657aead2f8>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    f.write(str(0.42 0.48 0.80 0.20))\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "with open('ans3.txt', 'w') as f:\n",
    "    r1 = '%.2f' % round(avg_rec_at_1_te_l, 2)\n",
    "    p1 = '%.2f' % round(avg_prec_at_1_te_l, 2)\n",
    "    r5 = '%.2f' % round(avg_rec_at_5_te_l, 2)\n",
    "    p5 = '%.2f' % round(avg_prec_at_5_te_l, 2)\n",
    "    ans3 = ' '.join([r1, p1, r5, p5])\n",
    "    print('Answer 3:', ans3)\n",
    "    f.write(ans3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
